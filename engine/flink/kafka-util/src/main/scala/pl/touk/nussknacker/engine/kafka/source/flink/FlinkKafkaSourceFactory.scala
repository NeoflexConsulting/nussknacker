package pl.touk.nussknacker.engine.kafka.source.flink

import org.apache.kafka.clients.consumer.ConsumerRecord
import pl.touk.nussknacker.engine.api.context.transformation.NodeDependencyValue
import pl.touk.nussknacker.engine.api.process.{ContextInitializer, ProcessObjectDependencies, Source}
import pl.touk.nussknacker.engine.flink.api.timestampwatermark.TimestampWatermarkHandler
import pl.touk.nussknacker.engine.kafka.{KafkaConfig, PreparedKafkaTopic, RecordFormatter, RecordFormatterFactory}
import pl.touk.nussknacker.engine.kafka.serialization.{KafkaDeserializationSchema, KafkaDeserializationSchemaFactory}
import pl.touk.nussknacker.engine.kafka.source.{KafkaContextInitializer, KafkaSourceFactory}

import scala.reflect.ClassTag

/**
  * Base factory for Kafka sources with additional metadata variable.
  * It is based on [[pl.touk.nussknacker.engine.api.context.transformation.SingleInputGenericNodeTransformation]]
  * that allows custom ValidationContext and Context transformations, which are provided by [[KafkaContextInitializer]]
  * Can be used for single- or multi- topic sources (as csv, see topicNameSeparator and extractTopics).
  *
  * Wrapper for [[org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer]]
  * Features:
  *   - fetch latest N records which can be later used to test process in UI
  *     Fetching data is defined in [[KafkaSource]] which
  *     extends [[pl.touk.nussknacker.engine.api.process.TestDataGenerator]]. See [[pl.touk.nussknacker.engine.kafka.KafkaUtils#readLastMessages]]
  *   - reset Kafka's offset to latest value - `forceLatestRead` property, see [[pl.touk.nussknacker.engine.kafka.KafkaUtils#setOffsetToLatest]]
  *
  * @param deserializationSchemaFactory - produces KafkaDeserializationSchema for raw [[KafkaSource]]
  * @param timestampAssigner            - provides timestampAsigner and WatermarkStrategy to KafkaSource
  * @param formatterFactory             - support for test data parser and generator
  * @param processObjectDependencies    - dependencies required by the component
  * @tparam K - type of key of kafka event that is generated by raw source (SourceFunction).
  * @tparam V - type of value of kafka event that is generated by raw source (SourceFunction).
  * */
class FlinkKafkaSourceFactory[K: ClassTag, V: ClassTag](protected val deserializationSchemaFactory: KafkaDeserializationSchemaFactory[ConsumerRecord[K, V]],
                                                        protected val timestampAssigner: Option[TimestampWatermarkHandler[ConsumerRecord[K, V]]],
                                                        protected val formatterFactory: RecordFormatterFactory,
                                                        protected val processObjectDependencies: ProcessObjectDependencies) extends KafkaSourceFactory[K, V] {

  override protected val keyClassTag: ClassTag[K] = implicitly[ClassTag[K]]

  override protected val valueClassTag: ClassTag[V] = implicitly[ClassTag[V]]

  override protected def createSource(params: Map[String, Any],
                                      dependencies: List[NodeDependencyValue],
                                      finalState: Option[KafkaSourceFactory.KafkaSourceFactoryState[K, V]],
                                      preparedTopics: List[PreparedKafkaTopic],
                                      kafkaConfig: KafkaConfig,
                                      deserializationSchema: KafkaDeserializationSchema[ConsumerRecord[K, V]],
                                      formatter: RecordFormatter,
                                      contextInitializer: ContextInitializer[ConsumerRecord[K, V]]): Source[ConsumerRecord[K, V]] =
    new ConsumerRecordBasedKafkaSource[K, V](preparedTopics, kafkaConfig, deserializationSchema, timestampAssigner, formatter, contextInitializer)

}